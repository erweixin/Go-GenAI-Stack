# @go-genai-stack/constants

Shared constants for Web and Mobile platforms.

## ğŸ“¦ åŒ…è¯´æ˜

è¿™ä¸ªåŒ…åŒ…å«è·¨ Web å’Œ Mobile å¹³å°ä½¿ç”¨çš„å¸¸é‡å®šä¹‰ã€‚

## ğŸš€ ä½¿ç”¨æ–¹å¼

### API ç«¯ç‚¹

```typescript
import { API_ENDPOINTS, buildUrl } from '@go-genai-stack/constants';

// ä½¿ç”¨ç«¯ç‚¹
fetch(API_ENDPOINTS.chat.send, {
  method: 'POST',
  body: JSON.stringify({ message: 'Hello' }),
});

// å¸¦å‚æ•°çš„ URL
const url = buildUrl(API_ENDPOINTS.chat.deleteConversation, { id: 'conv-123' });
// "/api/chat/conversations/conv-123/delete"
```

### é”™è¯¯ç 

```typescript
import { 
  ERROR_CODES, 
  getErrorMessage, 
  isUserError,
  isRateLimitError 
} from '@go-genai-stack/constants';

// æ£€æŸ¥é”™è¯¯ç±»å‹
if (isRateLimitError(errorCode)) {
  showRetryDialog();
}

// è·å–é”™è¯¯æ¶ˆæ¯
const message = getErrorMessage(ERROR_CODES.MESSAGE_EMPTY);
// "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"
```

### æ¨¡å‹å¸¸é‡

```typescript
import { 
  MODELS, 
  MODEL_METADATA, 
  getModelDisplayName,
  getModelsByCapability 
} from '@go-genai-stack/constants';

// ä½¿ç”¨æ¨¡å‹å¸¸é‡
const response = await llmApi.generate({
  model: MODELS.GPT4O,
  prompt: 'Hello',
});

// è·å–æ˜¾ç¤ºåç§°
getModelDisplayName(MODELS.GPT4O) // "GPT-4o"

// æŒ‰èƒ½åŠ›ç­›é€‰
const fastModels = getModelsByCapability('fast');
// ['gpt-4o-mini']
```

## ğŸ“‚ åŒ…å«çš„æ¨¡å—

- **api-endpoints.ts** - API è·¯å¾„å¸¸é‡
- **error-codes.ts** - é”™è¯¯ç å’Œé”™è¯¯æ¶ˆæ¯
- **models.ts** - LLM æ¨¡å‹ç›¸å…³å¸¸é‡

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ä¸åç«¯ä¿æŒåŒæ­¥**ï¼šå¸¸é‡å®šä¹‰åº”ä¸åç«¯ä¿æŒä¸€è‡´
2. **ä½¿ç”¨å¸¸é‡è€Œéç¡¬ç¼–ç **ï¼šé¿å…ç›´æ¥å†™å­—ç¬¦ä¸²
3. **TypeScript ç±»å‹å®‰å…¨**ï¼šå……åˆ†åˆ©ç”¨ `as const` å’Œç±»å‹æ¨å¯¼

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [Vibe Coding æœ€ä¼˜æ¶æ„](../../docs/optimal-architecture.md)
- [åç«¯é”™è¯¯ç å®šä¹‰](../../backend/domains/shared/errors)

